{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/kevin_smith/Desktop/FSU_Relevant_Stuff/fall_2023/CAP5771/project/gtzan/Data/features_30_sec.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Important Features:\n",
      "            Feature  Coefficient\n",
      "24       mfcc4_mean     0.249012\n",
      "27        mfcc5_var     0.235593\n",
      "28       mfcc6_mean     0.207043\n",
      "52      mfcc18_mean    -0.197398\n",
      "50      mfcc17_mean    -0.186486\n",
      "22       mfcc3_mean     0.168322\n",
      "2   chroma_stft_var     0.167185\n",
      "29        mfcc6_var     0.164697\n",
      "18       mfcc1_mean     0.145843\n",
      "44      mfcc14_mean     0.133247\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(['filename', 'label'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Standardize the features (optional but often recommended for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train an SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract coefficients from the SVM model\n",
    "coefficients = svm_model.coef_[0]\n",
    "\n",
    "# Create a DataFrame to store feature names and their corresponding coefficients\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': coefficients})\n",
    "\n",
    "# Sort the DataFrame by the absolute values of coefficients in descending order\n",
    "feature_importance_df = feature_importance_df.reindex(feature_importance_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Print the top N most important features and their coefficients\n",
    "top_n = 10  # Change this value to print a different number of top features\n",
    "print(f\"Top {top_n} Most Important Features:\")\n",
    "print(feature_importance_df.head(top_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Recall: 0.695\n",
      "F1 Score: 0.6927321363374466\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=pd.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(pd.unique(y_train), class_weights))\n",
    "\n",
    "# Initialize SVM model\n",
    "svm_model = SVC(class_weight=class_weight_dict)\n",
    "\n",
    "# Define scoring metrics (recall and F1 score)\n",
    "scoring = {'recall': make_scorer(recall_score, average='weighted'),\n",
    "           'f1_score': make_scorer(f1_score, average='weighted')}\n",
    "\n",
    "# Hyperparameter tuning using grid search\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'gamma': ['scale', 'auto', 0.1, 1, 10]}  # Adjust gamma for RBF kernel\n",
    "grid_search = GridSearchCV(svm_model, param_grid, scoring=scoring, cv=5, n_jobs=-1, refit='f1_score')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract the best model\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model performance\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Display the results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pytables'.  Use pip or conda to install pytables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/data_analysis/lib/python3.10/site-packages/pandas/compat/_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[1;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/data_analysis/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tables'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevin_smith/Desktop/FSU_Relevant_Stuff/fall_2023/CAP5771/project/source/proj.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kevin_smith/Desktop/FSU_Relevant_Stuff/fall_2023/CAP5771/project/source/proj.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_hdf(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/kevin_smith/Desktop/FSU_Relevant_Stuff/fall_2023/CAP5771/project/results/STFT_F1024_H520.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/data_analysis/lib/python3.10/site-packages/pandas/io/pytables.py:426\u001b[0m, in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exists:\n\u001b[1;32m    424\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mpath_or_buf\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 426\u001b[0m store \u001b[39m=\u001b[39m HDFStore(path_or_buf, mode\u001b[39m=\u001b[39;49mmode, errors\u001b[39m=\u001b[39;49merrors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    427\u001b[0m \u001b[39m# can't auto open/close if we are using an iterator\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39m# so delegate to the iterator\u001b[39;00m\n\u001b[1;32m    429\u001b[0m auto_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/data_analysis/lib/python3.10/site-packages/pandas/io/pytables.py:566\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mformat is not a defined argument for HDFStore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 566\u001b[0m tables \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mtables\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m complib \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m complib \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m tables\u001b[39m.\u001b[39mfilters\u001b[39m.\u001b[39mall_complibs:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomplib only supports \u001b[39m\u001b[39m{\u001b[39;00mtables\u001b[39m.\u001b[39mfilters\u001b[39m.\u001b[39mall_complibs\u001b[39m}\u001b[39;00m\u001b[39m compression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/data_analysis/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pytables'.  Use pip or conda to install pytables."
     ]
    }
   ],
   "source": [
    "df = pd.read_hdf(\"/Users/kevin_smith/Desktop/FSU_Relevant_Stuff/fall_2023/CAP5771/project/results/STFT_F1024_H520.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
